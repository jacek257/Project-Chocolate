{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import glob\n",
    "import multiprocessing\n",
    "import fnmatch\n",
    "import analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set limit for number of processes that can be run at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "limit = cores - 5 if cores > 8 else 1\n",
    "processes = [None] * limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grab the processed BOLD data, O2 contrast, and CO2 contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "71\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "bold_dir = '/home/ke/Desktop/all_bold/'\n",
    "shifted_dir = '/home/ke/Desktop/shifted_export/'\n",
    "\n",
    "# all grab all the .txt files in the bold folder\n",
    "bold_files = [str(file) for file in os.listdir(bold_dir) if file.upper().endswith('EDITS.TXT')]\n",
    "bold_files.sort()\n",
    "print(len(bold_files))\n",
    "O2_files = [file for file in os.listdir(shifted_dir) if file.upper().endswith('_O2.TXT')]\n",
    "O2_files.sort()\n",
    "print(len(O2_files))\n",
    "CO2_files = [file for file in os.listdir(shifted_dir) if file.upper().endswith('_CO2.TXT')]\n",
    "CO2_files.sort()\n",
    "print(len(CO2_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dir = '/home/ke/Desktop/feat/'\n",
    "T1_dir = '/home/ke/Desktop/all_T1/'\n",
    "\n",
    "# load design template\n",
    "with open(feat_dir+'design_files/template', 'r') as template:\n",
    "    stringTemp = template.read()\n",
    "    for i in range(len(bold_files)):\n",
    "        bold_path = bold_dir+'/'+bold_files[i]\n",
    "        bold_df = pd.read_csv(bold_path, names=['Time', 'BOLD'])\n",
    "        tr = bold_df.Time[1]\n",
    "        identify = bold_files[i].split('_')\n",
    "        sub_id = identify[0]\n",
    "        date = identify[1]\n",
    "        key = ''\n",
    "        verb = True\n",
    "        \n",
    "        output_dir = feat_dir+bold_files[i][:-4]\n",
    "        T1_file = [T1_dir+file for file in os.listdir(T1_dir) if fnmatch.fnmatch(file, sub_id+'_'+date+'*_T1.nii*')]\n",
    "        \n",
    "        if not T1_file:\n",
    "            T1_file = [T1_dir+file for file in os.listdir(T1_dir) if fnmatch.fnmatch(file, sub_id+'_FS_T1.nii*')]\n",
    "        \n",
    "        if not T1_file:\n",
    "            T1_file = ['/usr/local/fsl/data/standard/MNI152_T1_2mm_brain']\n",
    "        \n",
    "        T1_file = T1_file[0]\n",
    "#         print(T1_file)\n",
    "# #            output_dir = '/media/ke/8tb_part2/FSL_work/feat/both_shift/'+key+df.ID[i]+'_'+df.Date[i]\n",
    "#        if os.path.exists(output_dir+'.feat'):\n",
    "#            if verb:\n",
    "#                print('FEAT already exists for', key+df.ID[i]+'_'+df.Date[i])\n",
    "#            if over:\n",
    "#                if verb:\n",
    "#                    print('Overwriting')\n",
    "#                subprocess.run(['rm', '-rf', output_dir+'.feat'])\n",
    "#            else:\n",
    "#                continue\n",
    "        to_write = stringTemp[:]\n",
    "       # print(to_write)\n",
    "        to_write = to_write.replace(\"%%OUTPUT_DIR%%\",'\"'+output_dir+'\"')\n",
    "        to_write = to_write.replace(\"%%VOLUMES%%\",'\"'+str(len(bold_df))+'\"')\n",
    "        to_write = to_write.replace(\"%%TR%%\",'\"'+str(tr)+'\"')\n",
    "        to_write = to_write.replace(\"%%BOLD_FILE%%\",'\"'+bold_path+'\"')\n",
    "        to_write = to_write.replace(\"%%FS_T1%%\",'\"'+T1_file+'\"')\n",
    "        to_write = to_write.replace(\"%%O2_CONTRAST%%\",'\"'+O2_files[i]+'\"')\n",
    "        to_write = to_write.replace(\"%%CO2_CONTRAST%%\",'\"'+CO2_files[i]+'\"')\n",
    "\n",
    "        ds_path = feat_dir+'design_files/'+sub_id+'_'+date+'.fsf'\n",
    "        with open(ds_path, 'w+') as outFile:\n",
    "            outFile.write(to_write)\n",
    "\n",
    "        index = analysis.parallel_processing().get_next_avail(processes, verb, limit, key, 'FEAT')\n",
    "\n",
    "        if verb:\n",
    "            print('Starting FEAT')\n",
    "        processes[index] = subprocess.Popen(['feat', ds_path])\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    analysis.parallel_processing().wait_remaining(processes, verb, key, 'FEAT')\n",
    "\n",
    "# run featquery\n",
    "for i in range(len(bold_files)):\n",
    "    identify = bold_files[i].split('_')\n",
    "    sub_id = identify[0]\n",
    "    date = identify[1]\n",
    "    p_id = sub_id+'_'+date[i]\n",
    "    key = ''\n",
    "    verb = True\n",
    "    feat_output_dir = feat_dir+p_id+'.feat/'\n",
    "#        feat_output_dir = '/media/ke/8tb_part2/FSL_work/feat/both_shift/'+p_id+'.feat/'\n",
    "\n",
    "    O2_mask_dir_path = feat_output_dir+'cluster_mask_zstat1.nii.gz'\n",
    "    CO2_mask_dir_path = feat_output_dir+'cluster_mask_zstat2.nii.gz'\n",
    "\n",
    "    index = analysis.parallel_processing().get_next_avail(processes, verb, limit, key, 'featquery')\n",
    "\n",
    "    if os.path.exists(feat_output_dir+'fq_O2'):\n",
    "        if verb:\n",
    "            print('O2 featquery already exists for', p_id)\n",
    "        if over:\n",
    "            if verb:\n",
    "                print('Overwriting')\n",
    "            processes[index] = subprocess.Popen(['featquery', '1', feat_output_dir, '1', 'stats/cope1', 'fq_O2', '-p', '-s', O2_mask_dir_path])\n",
    "    else:\n",
    "        if verb:\n",
    "            print('Starting O2 featquery for', p_id)\n",
    "        processes[index] = subprocess.Popen(['featquery', '1', feat_output_dir, '1', 'stats/cope1', 'fq_O2', '-p', '-s', O2_mask_dir_path])\n",
    "\n",
    "    index = analysis.parallel_processing().get_next_avail(processes, verb, limit, key, 'featquery')\n",
    "\n",
    "    if os.path.exists(feat_output_dir+'fq_CO2'):\n",
    "        if verb:\n",
    "            print('CO2 featquery already exists for', p_id)\n",
    "        if over:\n",
    "            if verb:\n",
    "                print('Overwriting')\n",
    "            processes[index] = subprocess.Popen(['featquery', '1', feat_output_dir, '1', 'stats/cope2', 'fq_CO2', '-p', '-s', CO2_mask_dir_path])\n",
    "    else:\n",
    "        if verb:\n",
    "            print('Starting featquery for CO2')\n",
    "        processes[index] = subprocess.Popen(['featquery', '1', feat_output_dir, '1', 'stats/cope2', 'fq_CO2', '-p', '-s', CO2_mask_dir_path])\n",
    "\n",
    "\n",
    "analysis.parallel_processing().wait_remaining(processes, verb, key, 'featquery')\n",
    "\n",
    "# get the stats\n",
    "for i in range(len(bold_files)):\n",
    "    identify = bold_files[i].split('_')\n",
    "    sub_id = identify[0]\n",
    "    date = identify[1]\n",
    "    p_id = sub_id+'_'+date[i]      \n",
    "    add = True\n",
    "    key = ''\n",
    "    verb = True\n",
    "    feat_output_dir = feat_dir+p_id+'.feat/'\n",
    "#        output_dir = '/media/ke/8tb_part2/FSL_work/feat/both_shift/'+key+df.ID[i]+'_'+df.Date[i]\n",
    "#     feat_output_dir = output_dir+'.feat/'\n",
    "\n",
    "    try:\n",
    "        cz1 = pd.read_csv(feat_output_dir+'cluster_zstat1.txt', sep='\\t', usecols=['Voxels', '-log10(P)', 'Z-MAX', 'COPE-MEAN'])\n",
    "        t_vol = cz1.Voxels.sum()\n",
    "\n",
    "        for j in range(len(cz1)):\n",
    "            cz1.iloc[j] = cz1.iloc[j] * cz1.iloc[j].Voxels/t_vol\n",
    "\n",
    "\n",
    "        z1 = { 'ID' : [p_id],\n",
    "               'Voxels': [t_vol],\n",
    "               '-log10(p)' : [cz1['-log10(P)'].sum()],\n",
    "               'COPE-MEAN' : [cz1['COPE-MEAN'].sum()]}\n",
    "        cz1_final = pd.DataFrame(z1)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        warnings['ID'].append(p_id)\n",
    "        warnings['warning'].append('No cluster_zstat1.txt')\n",
    "        add = False\n",
    "        if verb:\n",
    "            print('No cluster_zstat1.txt', p_id)\n",
    "\n",
    "    try:\n",
    "        cz2 = pd.read_csv(feat_output_dir+'cluster_zstat2.txt', sep='\\t', usecols=['Voxels', '-log10(P)', 'Z-MAX', 'COPE-MEAN'])\n",
    "        t_vol = cz2.Voxels.sum()\n",
    "\n",
    "        for j in range(len(cz2)):\n",
    "            cz2.iloc[j] = cz2.iloc[j] * cz2.iloc[j].Voxels/t_vol\n",
    "\n",
    "\n",
    "        z2 = { 'ID' : [p_id],\n",
    "               'Voxels': [t_vol],\n",
    "               '-log10(p)' : [cz2['-log10(P)'].sum()],\n",
    "               'COPE-MEAN' : [cz2['COPE-MEAN'].sum()]}\n",
    "        cz2_final = pd.DataFrame(z2)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        warnings['ID'].append(p_id)\n",
    "        warnings['warning'].append('No cluster_zstat2.txt')\n",
    "        add = False\n",
    "        if verb:\n",
    "            print('No cluster_zstat2.txt', p_id\n",
    "\n",
    "    build = cz1_final.merge(cz2_final, on=['ID'], suffixes=('_O2', '_CO2'))\n",
    "\n",
    "    O2_mask_dir_path = feat_output_dir+'cluster_mask_zstat1.nii.gz'\n",
    "    CO2_mask_dir_path = feat_output_dir+'cluster_mask_zstat2.nii.gz'\n",
    "\n",
    "    O2 = feat_output_dir+'fq_O2/'\n",
    "    try:\n",
    "        fq1 = pd.read_csv(O2+'report.txt', sep='\\t| ', header=None, usecols=[5], engine='python')\n",
    "        fq1 = fq1.rename(columns={5 : 'fq_mean'})\n",
    "        fq1['ID'] = p_id\n",
    "        fq1 = fq1[['ID', 'fq_mean']]\n",
    "        build = build.merge(fq1, on=['ID'], suffixes=('_O2', '_CO2'))\n",
    "    except FileNotFoundError:\n",
    "        warnings['ID'].append(p_id)\n",
    "        warnings['warning'].append('No O2 activation found')\n",
    "        add = False\n",
    "        if verb:\n",
    "            print('No O2 activation found for', p_id, 'O2')\n",
    "\n",
    "\n",
    "    CO2 = feat_output_dir+'fq_CO2/'\n",
    "    try:\n",
    "        fq2 = pd.read_csv(CO2+'report.txt', sep='\\t| ', header=None, usecols=[5], engine='python')\n",
    "        fq2 = fq2.rename(columns={5 : 'fq_mean'})\n",
    "        fq2['ID'] = df.ID[i]+'_'+df.Date[i]\n",
    "        fq2['type'] = key\n",
    "        fq2 = fq2[['ID', 'type', 'fq_mean']]\n",
    "        build = build.merge(fq2, on=['ID', 'type'], suffixes=('_O2', '_CO2'))\n",
    "    except FileNotFoundError:\n",
    "        warnings['ID'].append(df.ID[i] + '_' + df.Date[i])\n",
    "        warnings['warning'].append('No CO2 activation found')\n",
    "        add = False\n",
    "        if verb:\n",
    "            print('No CO2 activation found for', df.ID[i] + '_' + df.Date[i], 'O2')\n",
    "\n",
    "    build['O2_shift'] = df.O2_shift[i]\n",
    "    build['CO2_shift'] = df.CO2_shift[i]\n",
    "    build['O2_coeff'] = df.coeffs[i][0]\n",
    "    build['CO2_coeff'] = df.coeffs[i][1]\n",
    "    build['r'] = df.r[i]\n",
    "    build['p_value'] = df.p_value[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    if verb:\n",
    "#        print('\\n\\nStarting to run feat')\n",
    "#    #run Feat\n",
    "#    #check for (and make) feat directory\n",
    "#    if not os.path.exists(feat_dir):\n",
    "#        os.mkdir(feat_dir)\n",
    "#    \n",
    "#    #make design file directory\n",
    "#    if not os.path.exists(feat_dir+'design_files/'):\n",
    "#        os.mkdir(feat_dir+'design_files/')\n",
    "#    \n",
    "#    # load design template\n",
    "#    with open(feat_dir+'design_files/template', 'r') as template:\n",
    "#        stringTemp = template.read()\n",
    "#        for i in range(len(df)):\n",
    "#            output_dir = feat_dir+key+df.ID[i]+'_'+df.Date[i]\n",
    "##            output_dir = '/media/ke/8tb_part2/FSL_work/feat/both_shift/'+key+df.ID[i]+'_'+df.Date[i]\n",
    "#            if os.path.exists(output_dir+'.feat'):\n",
    "#                if verb:\n",
    "#                    print('FEAT already exists for', key+df.ID[i]+'_'+df.Date[i])\n",
    "#                if over:\n",
    "#                    if verb:\n",
    "#                        print('Overwriting')\n",
    "#                    subprocess.run(['rm', '-rf', output_dir+'.feat'])\n",
    "#                else:\n",
    "#                    continue\n",
    "#            to_write = stringTemp[:]\n",
    "#            # print(to_write)\n",
    "#            to_write = to_write.replace(\"%%OUTPUT_DIR%%\",'\"'+output_dir+'\"')\n",
    "#            to_write = to_write.replace(\"%%VOLUMES%%\",'\"'+str(df.Volumes[i])+'\"')\n",
    "#            to_write = to_write.replace(\"%%TR%%\",'\"'+str(df.eff_TR[i])+'\"')\n",
    "#            to_write = to_write.replace(\"%%BOLD_FILE%%\",'\"'+df.BOLD_path[i]+'\"')\n",
    "#            to_write = to_write.replace(\"%%FS_T1%%\",'\"'+df.T1_path[i]+'\"')\n",
    "#            to_write = to_write.replace(\"%%O2_CONTRAST%%\",'\"'+df.ETO2[i]+'\"')\n",
    "#            to_write = to_write.replace(\"%%CO2_CONTRAST%%\",'\"'+df.ETCO2[i]+'\"')\n",
    "#    \n",
    "#            ds_path = feat_dir+'design_files/'+key+df.ID[i]+'_'+df.Date[i]+'.fsf'\n",
    "#            with open(ds_path, 'w+') as outFile:\n",
    "#                outFile.write(to_write)\n",
    "#                        \n",
    "#            index = analysis.parallel_processing().get_next_avail(processes, verb, limit, key, 'FEAT')\n",
    "#            \n",
    "#            if verb:\n",
    "#                print('Starting FEAT')\n",
    "#            processes[index] = subprocess.Popen(['feat', ds_path])\n",
    "#            time.sleep(0.5)\n",
    "#        \n",
    "#        analysis.parallel_processing().wait_remaining(processes, verb, key, 'FEAT')\n",
    "#        \n",
    "#    # run featquery\n",
    "#    for i in range(len(df)):\n",
    "#        p_id = key+df.ID[i]+'_'+df.Date[i]\n",
    "#        feat_output_dir = feat_dir+p_id+'.feat/'\n",
    "##        feat_output_dir = '/media/ke/8tb_part2/FSL_work/feat/both_shift/'+p_id+'.feat/'\n",
    "#        \n",
    "#        O2_mask_dir_path = feat_output_dir+'cluster_mask_zstat1.nii.gz'\n",
    "#        CO2_mask_dir_path = feat_output_dir+'cluster_mask_zstat2.nii.gz'\n",
    "#                    \n",
    "#        index = analysis.parallel_processing().get_next_avail(processes, verb, limit, key, 'featquery')\n",
    "#        \n",
    "#        if os.path.exists(feat_output_dir+'fq_O2'):\n",
    "#            if verb:\n",
    "#                print('O2 featquery already exists for', p_id)\n",
    "#            if over:\n",
    "#                if verb:\n",
    "#                    print('Overwriting')\n",
    "#                processes[index] = subprocess.Popen(['featquery', '1', feat_output_dir, '1', 'stats/cope1', 'fq_O2', '-p', '-s', O2_mask_dir_path])\n",
    "#        else:\n",
    "#            if verb:\n",
    "#                print('Starting O2 featquery for', p_id)\n",
    "#            processes[index] = subprocess.Popen(['featquery', '1', feat_output_dir, '1', 'stats/cope1', 'fq_O2', '-p', '-s', O2_mask_dir_path])\n",
    "#        \n",
    "#        index = analysis.parallel_processing().get_next_avail(processes, verb, limit, key, 'featquery')\n",
    "#        \n",
    "#        if os.path.exists(feat_output_dir+'fq_CO2'):\n",
    "#            if verb:\n",
    "#                print('CO2 featquery already exists for', p_id)\n",
    "#            if over:\n",
    "#                if verb:\n",
    "#                    print('Overwriting')\n",
    "#                processes[index] = subprocess.Popen(['featquery', '1', feat_output_dir, '1', 'stats/cope2', 'fq_CO2', '-p', '-s', CO2_mask_dir_path])\n",
    "#        else:\n",
    "#            if verb:\n",
    "#                print('Starting featquery for CO2')\n",
    "#            processes[index] = subprocess.Popen(['featquery', '1', feat_output_dir, '1', 'stats/cope2', 'fq_CO2', '-p', '-s', CO2_mask_dir_path])\n",
    "#    \n",
    "#\n",
    "#    analysis.parallel_processing().wait_remaining(processes, verb, key, 'featquery')\n",
    "        \n",
    "#     # get the stats\n",
    "#     for i in range(len(df)):        \n",
    "#         add = True\n",
    "        \n",
    "#        output_dir = feat_dir+key+df.ID[i]+'_'+df.Date[i]\n",
    "##        output_dir = '/media/ke/8tb_part2/FSL_work/feat/both_shift/'+key+df.ID[i]+'_'+df.Date[i]\n",
    "#        feat_output_dir = output_dir+'.feat/'\n",
    "#        \n",
    "#        try:\n",
    "#            cz1 = pd.read_csv(feat_output_dir+'cluster_zstat1.txt', sep='\\t', usecols=['Voxels', '-log10(P)', 'Z-MAX', 'COPE-MEAN'])\n",
    "#            t_vol = cz1.Voxels.sum()\n",
    "#            \n",
    "#            for j in range(len(cz1)):\n",
    "#                cz1.iloc[j] = cz1.iloc[j] * cz1.iloc[j].Voxels/t_vol\n",
    "#            \n",
    "#\n",
    "#            z1 = { 'ID' : [df.ID[i]+'_'+df.Date[i]],\n",
    "#                   'type' : [key],\n",
    "#                   'Voxels': [t_vol],\n",
    "#                   '-log10(p)' : [cz1['-log10(P)'].sum()],\n",
    "#                   'COPE-MEAN' : [cz1['COPE-MEAN'].sum()]}\n",
    "#            cz1_final = pd.DataFrame(z1)\n",
    "#        \n",
    "#        except FileNotFoundError:\n",
    "#            warnings['ID'].append(df.ID[i] + '_' + df.Date[i])\n",
    "#            warnings['warning'].append('No cluster_zstat1.txt')\n",
    "#            add = False\n",
    "#            if verb:\n",
    "#                print('No cluster_zstat1.txt')\n",
    "#        \n",
    "#        try:\n",
    "#            cz2 = pd.read_csv(feat_output_dir+'cluster_zstat2.txt', sep='\\t', usecols=['Voxels', '-log10(P)', 'Z-MAX', 'COPE-MEAN'])\n",
    "#            t_vol = cz2.Voxels.sum()\n",
    "#            \n",
    "#            for j in range(len(cz2)):\n",
    "#                cz2.iloc[j] = cz2.iloc[j] * cz2.iloc[j].Voxels/t_vol\n",
    "#            \n",
    "#\n",
    "#            z2 = { 'ID' : [df.ID[i]+'_'+df.Date[i]],\n",
    "#                   'type' : [key],\n",
    "#                   'Voxels': [t_vol],\n",
    "#                   '-log10(p)' : [cz2['-log10(P)'].sum()],\n",
    "#                   'COPE-MEAN' : [cz2['COPE-MEAN'].sum()]}\n",
    "#            cz2_final = pd.DataFrame(z2)\n",
    "#        \n",
    "#        except FileNotFoundError:\n",
    "#            warnings['ID'].append(df.ID[i] + '_' + df.Date[i])\n",
    "#            warnings['warning'].append('No cluster_zstat2.txt')\n",
    "#            add = False\n",
    "#            if verb:\n",
    "#                print('No cluster_zstat2.txt', df.ID[i], '_', df.Date[i])\n",
    "#        \n",
    "#        build = cz1_final.merge(cz2_final, on=['ID', 'type'], suffixes=('_O2', '_CO2'))\n",
    "#        \n",
    "#        O2_mask_dir_path = feat_output_dir+'cluster_mask_zstat1.nii.gz'\n",
    "#        CO2_mask_dir_path = feat_output_dir+'cluster_mask_zstat2.nii.gz'\n",
    "#            \n",
    "#        O2 = feat_output_dir+'fq_O2/'\n",
    "#        try:\n",
    "#            fq1 = pd.read_csv(O2+'report.txt', sep='\\t| ', header=None, usecols=[5], engine='python')\n",
    "#            fq1 = fq1.rename(columns={5 : 'fq_mean'})\n",
    "#            fq1['ID'] = df.ID[i]+'_'+df.Date[i]\n",
    "#            fq1['type'] = key\n",
    "#            fq1 = fq1[['ID', 'type', 'fq_mean']]\n",
    "#            build = build.merge(fq1, on=['ID', 'type'], suffixes=('_O2', '_CO2'))\n",
    "#        except FileNotFoundError:\n",
    "#            warnings['ID'].append(df.ID[i] + '_' + df.Date[i])\n",
    "#            warnings['warning'].append('No O2 activation found')\n",
    "#            add = False\n",
    "#            if verb:\n",
    "#                print('No O2 activation found for', df.ID[i] + '_' + df.Date[i], 'O2')\n",
    "#        \n",
    "#            \n",
    "#        CO2 = feat_output_dir+'fq_CO2/'\n",
    "#        try:\n",
    "#            fq2 = pd.read_csv(CO2+'report.txt', sep='\\t| ', header=None, usecols=[5], engine='python')\n",
    "#            fq2 = fq2.rename(columns={5 : 'fq_mean'})\n",
    "#            fq2['ID'] = df.ID[i]+'_'+df.Date[i]\n",
    "#            fq2['type'] = key\n",
    "#            fq2 = fq2[['ID', 'type', 'fq_mean']]\n",
    "#            build = build.merge(fq2, on=['ID', 'type'], suffixes=('_O2', '_CO2'))\n",
    "#        except FileNotFoundError:\n",
    "#            warnings['ID'].append(df.ID[i] + '_' + df.Date[i])\n",
    "#            warnings['warning'].append('No CO2 activation found')\n",
    "#            add = False\n",
    "#            if verb:\n",
    "#                print('No CO2 activation found for', df.ID[i] + '_' + df.Date[i], 'O2')\n",
    "#        \n",
    "#        build['O2_shift'] = df.O2_shift[i]\n",
    "#        build['CO2_shift'] = df.CO2_shift[i]\n",
    "#        build['O2_coeff'] = df.coeffs[i][0]\n",
    "#        build['CO2_coeff'] = df.coeffs[i][1]\n",
    "#        build['r'] = df.r[i]\n",
    "#        build['p_value'] = df.p_value[i]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
